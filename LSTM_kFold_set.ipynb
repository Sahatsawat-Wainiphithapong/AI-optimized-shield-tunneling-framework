{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPcwpezc40rpv0ij9H7kREI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chain28/UNDSP-D-25-00030/blob/main/LSTM_kFold_set.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#README"
      ],
      "metadata": {
        "id": "4yidqGaLZndu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook provides an example of Python scripts for training an LSTM model, including a k-fold cross-validation approach to ensure thorough assessment of the modelâ€™s performance. In this demonstration, ground surface settlement is used as the target variable.\n",
        "\n",
        "It should be noted that the code combines essential functions for LSTM training with additional procedures for gathering and displaying results. As a result, running the notebook may take some time due to the computational load from cross-validation and visualization tasks."
      ],
      "metadata": {
        "id": "rKIWZ4L_ZzBw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Mount Google Drive"
      ],
      "metadata": {
        "id": "xouKE1y7uoxu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJjMFeI-uvhE",
        "outputId": "313aee79-a96b-4b97-b236-64bc2674b465"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import libraries"
      ],
      "metadata": {
        "id": "69__Ji2wu0UT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import GRU, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.callbacks import Callback"
      ],
      "metadata": {
        "id": "D2DBXh-Ku4g6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Setting"
      ],
      "metadata": {
        "id": "uJ2NCNcMvGfQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =====[GENERAL SETTING]=====\n",
        "TARGET = \"SET\"      # [PEN or SET]\n",
        "dlMOD  = \"LSTM\"     # [LSTM OR GRU]\n",
        "NOTICE = 0          # [0 or 1]\n",
        "\n",
        "# =====[FILE PATH AND NAME SETTING]=====\n",
        "NAME_DATASET = \"BL - 25 cases\"\n",
        "NAME_CASE    = \"BL - 25 cases\"\n",
        "\n",
        "# =====[TIMESTEP SETTING]=====\n",
        "if TARGET == \"SET\":\n",
        "  PTS, NTS, CTS = 5, 5, 1\n",
        "elif TARGET == \"PEN\":\n",
        "  PTS, NTS, CTS = 0, 0, 1\n",
        "\n",
        "SEQ = PTS+NTS+CTS # Total timestep in one sequence\n",
        "\n",
        "# =====[K-FOLD SETTING]=====\n",
        "num_FOLD = 5 # Amount of fold for using in k-fold cross-validation process\n",
        "\n",
        "# =====[DEEP LEARNING SETTING]=====\n",
        "EPOCHS  = 1000\n",
        "PATIENT = 100\n",
        "DROPOUT = 0.2\n",
        "OPTIM   = \"adam\"\n",
        "LOSS    = \"mse\"\n",
        "METRIC  = [\"mse\", \"mape\"]\n",
        "ATV_FUNC = [\"relu\", \"sigmoid\", \"linear\"]\n",
        "\n",
        "ARCH_LIST = [[32, 32, 16, 1],               #Architecture No.01\n",
        "              [64, 64, 32, 1],              #Architecture No.02\n",
        "              [128, 128, 64, 1],            #Architecture No.03\n",
        "              [32, 32, 16, 8, 1],           #Architecture No.04\n",
        "              [64, 64, 32, 16, 1],          #Architecture No.05\n",
        "              [128, 128, 64, 32, 1],        #Architecture No.06\n",
        "              [32, 32, 16, 8, 4, 1],        #Architecture No.07\n",
        "              [64, 64, 32, 16, 8, 1],       #Architecture No.08\n",
        "              [128, 128, 64, 32, 16, 1],    #Architecture No.09\n",
        "              ]\n",
        "\n",
        "# =====[DATASET RATIO FOR BEST MODEL TRAINING]=====\n",
        "if TARGET == \"SET\":\n",
        "  RATIO_num_val = 5 # Approx. 20% of 25 dataset for settlement prediction\n",
        "elif TARGET == \"PEN\":\n",
        "  RATIO_num_val = 54 # Approx. 20% of 268 dataset for penetration rate prediction\n",
        "\n",
        "# =====[VISUAL SETTING]=====\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)"
      ],
      "metadata": {
        "id": "T6ShMJ0JvIq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Part-I: k-fold cross-validation"
      ],
      "metadata": {
        "id": "Fz-Cb9mWSDAG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Define function"
      ],
      "metadata": {
        "id": "3SlN_r5q4c-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def imp_trainData():\n",
        "  global NAME_DATASET, TARGET, SEQ\n",
        "  if TARGET == \"SET\":\n",
        "    df_f = pd.read_excel(f\"/content/drive/MyDrive/Paper/01_Prediction - Dataset/Feature_{NAME_DATASET} - set.xlsx\")\n",
        "    df_t = pd.read_excel(f\"/content/drive/MyDrive/Paper/01_Prediction - Dataset/Target_{NAME_DATASET} - set.xlsx\")\n",
        "  elif TARGET == \"PEN\":\n",
        "    df_f = pd.read_excel(f\"/content/drive/MyDrive/Paper/01_Prediction - Dataset/Feature_{NAME_DATASET} - pen.xlsx\")\n",
        "    df_t = pd.read_excel(f\"/content/drive/MyDrive/Paper/01_Prediction - Dataset/Target_{NAME_DATASET} - pen.xlsx\")\n",
        "\n",
        "  X   = df_f.values\n",
        "\n",
        "  num_SEQ = X.shape[0]//SEQ\n",
        "\n",
        "  X_t = X.reshape(((num_SEQ), SEQ, X.shape[1]))\n",
        "  y_t = df_t.values.squeeze()\n",
        "  return X_t, y_t, num_SEQ\n",
        "\n",
        "def model_arch(X_train, ARCH_NO, sel_ARCH):\n",
        "  global EPOCHS, PATIENT, DROPOUT, OPTIM, LOSS, METRIC, ATV_FUNC, ARCH_LIST, num_SEQ\n",
        "\n",
        "  num_CELL = sel_ARCH[0]\n",
        "  num_MLP  = sel_ARCH[1:]\n",
        "\n",
        "  model = tf.keras.Sequential()\n",
        "  if dlMOD == \"LSTM\":\n",
        "    model.add(LSTM(num_CELL, activation=ATV_FUNC[0], input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "  if dlMOD == \"GRU\":\n",
        "    model.add(GRU(num_CELL, activation=ATV_FUNC[0], input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "\n",
        "  model.add(Dropout(DROPOUT))\n",
        "\n",
        "  for i, cell in enumerate(num_MLP):\n",
        "    if cell != 1:\n",
        "      model.add(Dense(cell, activation=ATV_FUNC[1]))\n",
        "    elif cell == 1:\n",
        "      model.add(Dense(1, activation=ATV_FUNC[2]))\n",
        "\n",
        "  model.compile(optimizer=OPTIM, loss=LOSS, metrics=METRIC)\n",
        "  model.summary()\n",
        "  return model\n",
        "\n",
        "def model_callback(ARCH_NO, fold):\n",
        "  global dlMOD, TARGET\n",
        "  path = f\"/content/drive/MyDrive/Paper/02_Prediction - Model/{NAME_CASE}/Callback_{dlMOD} - {TARGET} - ARCH {ARCH_NO+1} Fold {fold+1}.keras\"\n",
        "  callback = [EarlyStopping(monitor=\"val_loss\", patience=PATIENT),\n",
        "              ModelCheckpoint(path, monitor=\"val_loss\", save_best_only=True, mode=\"min\")]\n",
        "  return callback\n",
        "\n",
        "def model_fitting(model, callback, X_train, y_train, X_val, y_val):\n",
        "  global EPOCHS, NOTICE\n",
        "  history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=EPOCHS, callbacks=callback, verbose=NOTICE)\n",
        "\n",
        "  plt.plot(history.history[\"loss\"], label=\"Training Loss\", color=\"b\")\n",
        "  plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\", color=\"darkorange\")\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "  return history\n",
        "\n",
        "def model_load(ARCH_NO, fold):\n",
        "  global dlMOD, TARGET, NAME_CASE\n",
        "  model = load_model(f\"/content/drive/MyDrive/Paper/02_Prediction - Model/{NAME_CASE}/Callback_{dlMOD} - {TARGET} - ARCH {ARCH_NO+1} Fold {fold+1}.keras\")\n",
        "  return model\n",
        "\n",
        "def model_evaluation(model, X_train, y_train, X_val, y_val, ARCH_NO, fold):\n",
        "  global dlMOD, TARGET, NAME_CASE\n",
        "  list_df_X = [X_train, X_val]\n",
        "  list_df_y = [y_train, y_val]\n",
        "  df_eval = pd.DataFrame()\n",
        "  # >> Use MSE and MAPE for evaluation in this case\n",
        "  for i in range(2):\n",
        "    MSE_loss, MSE_metric, MAPE_metric = model.evaluate(list_df_X[i],list_df_y[i])\n",
        "    df = pd.DataFrame({\"MSE_loss\": [MSE_loss], \"MSE_metric\": [MSE_metric], \"MAPE_metric\": [MAPE_metric]})\n",
        "    df_eval = pd.concat([df_eval, df], axis=0)\n",
        "    df_eval = df_eval.rename(index={\"row1\": \"trainDataset\", \"row2\": \"valDataset\"})\n",
        "\n",
        "  df_eval.to_excel(f\"/content/drive/MyDrive/Paper/03_Prediction - Result/{NAME_CASE}/Loss Evaluation - {dlMOD} - {TARGET} - ARCH {ARCH_NO+1} - Fold {fold+1}.xlsx\", index=False)"
      ],
      "metadata": {
        "id": "wYst8bmu4kaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run"
      ],
      "metadata": {
        "id": "aAf40SACSVln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_t, y_t, num_SEQ = imp_trainData()\n",
        "\n",
        "for ARCH_NO, sel_ARCH in enumerate(ARCH_LIST, start=0):\n",
        "  kf = KFold(n_splits=num_FOLD, shuffle=True, random_state=42)\n",
        "\n",
        "  df_train, df_val = pd.DataFrame(), pd.DataFrame()\n",
        "  df_train_loss, df_train_metric, df_val_loss, df_val_metric = pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n",
        "\n",
        "  for fold, (train_ind, val_ind) in enumerate(kf.split(X_t), start=0):\n",
        "\n",
        "    # Split dataset\n",
        "    X_train, X_val = X_t[train_ind], X_t[val_ind]\n",
        "    y_train, y_val = y_t[train_ind], y_t[val_ind]\n",
        "\n",
        "    # Index record\n",
        "    df_train_new = pd.DataFrame(train_ind)\n",
        "    df_train = pd.concat([df_train, df_train_new], axis=1)\n",
        "    df_val_new = pd.DataFrame(val_ind)\n",
        "    df_val = pd.concat([df_val, df_val_new], axis=1)\n",
        "\n",
        "    # Training\n",
        "    print(f\" Architecture No.0{ARCH_NO+1} - Fold{fold+1}\")\n",
        "    model = model_arch(X_train, ARCH_NO, sel_ARCH)\n",
        "    callback = model_callback(ARCH_NO, fold)\n",
        "    history = model_fitting(model, callback, X_train, y_train, X_val, y_val)\n",
        "\n",
        "    # Loss and metric record\n",
        "    df_train_loss_new = pd.DataFrame(history.history[\"loss\"])\n",
        "    df_train_loss = pd.concat([df_train_loss, df_train_loss_new], axis=1)\n",
        "    df_val_loss_new = pd.DataFrame(history.history[\"val_loss\"])\n",
        "    df_val_loss = pd.concat([df_val_loss, df_val_loss_new], axis=1)\n",
        "    df_train_metric_new = pd.DataFrame(history.history[\"mape\"])\n",
        "    df_train_metric = pd.concat([df_train_metric, df_train_metric_new], axis=1)\n",
        "    df_val_metric_new = pd.DataFrame(history.history[\"val_mape\"])\n",
        "    df_val_metric = pd.concat([df_val_metric, df_val_metric_new], axis=1)\n",
        "\n",
        "    if fold + 1 == num_FOLD:\n",
        "      df_train.columns = [f\"Fold{i+1}\" for i in range(num_FOLD)]\n",
        "      df_val.columns   = [f\"Fold{i+1}\" for i in range(num_FOLD)]\n",
        "      df_train.to_excel(f\"/content/drive/MyDrive/Paper/03_Prediction - Result/{NAME_CASE}/Index_kFold - {dlMOD} - {TARGET} - ARCH {ARCH_NO+1} - train.xlsx\")\n",
        "      df_val.to_excel(f\"/content/drive/MyDrive/Paper/03_Prediction - Result/{NAME_CASE}/Index_kFold - {dlMOD} - {TARGET} - ARCH {ARCH_NO+1} - val.xlsx\")\n",
        "\n",
        "      df_train_loss.columns   = [f\"Fold{i+1}\" for i in range(num_FOLD)]\n",
        "      df_val_loss.columns     = [f\"Fold{i+1}\" for i in range(num_FOLD)]\n",
        "      df_train_metric.columns = [f\"Fold{i+1}\" for i in range(num_FOLD)]\n",
        "      df_val_metric.columns   = [f\"Fold{i+1}\" for i in range(num_FOLD)]\n",
        "\n",
        "      df_train_loss.to_excel(f\"/content/drive/MyDrive/Paper/03_Prediction - Result/{NAME_CASE}/Loss Record - {dlMOD} - {TARGET} - ARCH {ARCH_NO+1} - train.xlsx\")\n",
        "      df_val_loss.to_excel(f\"/content/drive/MyDrive/Paper/03_Prediction - Result/{NAME_CASE}/Loss Record - {dlMOD} - {TARGET} - ARCH {ARCH_NO+1} - val.xlsx\")\n",
        "      df_train_metric.to_excel(f\"/content/drive/MyDrive/Paper/03_Prediction - Result/{NAME_CASE}/Metric Record - {dlMOD} - {TARGET} - ARCH {ARCH_NO+1} - train.xlsx\")\n",
        "      df_val_metric.to_excel(f\"/content/drive/MyDrive/Paper/03_Prediction - Result/{NAME_CASE}/Metric Record - {dlMOD} - {TARGET} - ARCH {ARCH_NO+1} - val.xlsx\")\n",
        "\n",
        "    model_trained = model_load(ARCH_NO, fold)\n",
        "    model_evaluation(model_trained, X_train, y_train, X_val, y_val, ARCH_NO, fold)"
      ],
      "metadata": {
        "id": "Br6L-UpU61Tg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Part-II: Best model selection"
      ],
      "metadata": {
        "id": "8AtpQYKkRbKb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Define function"
      ],
      "metadata": {
        "id": "SL76SgGWSgN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def best_eval():\n",
        "  global NAME_CASE, dlMOD, TARGET\n",
        "  df_kfold_eval = pd.DataFrame()\n",
        "\n",
        "  for ARCH_NO, _ in enumerate(ARCH_LIST, start=1):\n",
        "    df = pd.DataFrame()\n",
        "\n",
        "    for fold in range(1,(num_FOLD+1)):\n",
        "      df_error = pd.DataFrame()\n",
        "      df_new   = pd.read_excel(f\"/content/drive/MyDrive/Paper/03_Prediction - Result/{NAME_CASE}/Loss Evaluation - {dlMOD} - {TARGET} - ARCH {ARCH_NO} - Fold {fold}.xlsx\", index_col=None)\n",
        "      df_error = pd.DataFrame([[df_new.iat[1,0], df_new.iat[1,-1]]]) # Use validation dataset error to evaluate [MSE, MAPE]\n",
        "      df       = pd.concat([df, df_error], axis=0)\n",
        "\n",
        "    avg_MSE       = df.iloc[:,0].mean()\n",
        "    avg_MAPE      = df.iloc[:,1].mean()\n",
        "    df_avg        = pd.DataFrame({\"Average MSE\": [avg_MSE], \"Average MAPE\":[avg_MAPE]})\n",
        "    df_kfold_eval = pd.concat([df_kfold_eval, df_avg], axis=0)\n",
        "\n",
        "  df_kfold_eval   = df_kfold_eval.reset_index(drop=True)\n",
        "  df_kfold_eval.to_excel(f\"/content/drive/MyDrive/Paper/03_Prediction - Result/{NAME_CASE}/k-fold Evaluation - {dlMOD} - {TARGET} - All ARCH.xlsx\")\n",
        "\n",
        "  min_MSE     = df_kfold_eval.iloc[:,0].min()\n",
        "  min_MAPE    = df_kfold_eval.iloc[:,1].min()\n",
        "  minInd_MSE  = df_kfold_eval.iloc[:,0].idxmin()\n",
        "  minInd_MAPE = df_kfold_eval.iloc[:,1].idxmin()\n",
        "\n",
        "  print(f\"Minimum MSE index: {minInd_MSE} = ARCH No.{minInd_MSE+1} // MSE={min_MSE}\")\n",
        "  print(f\"Minimum MAPE index: {minInd_MAPE}  = ARCH No.{minInd_MAPE+1} // MAPE={min_MAPE}\")\n",
        "  return minInd_MSE, minInd_MAPE\n",
        "\n",
        "def best_model_arch(minInd_MSE):\n",
        "  global ARCH_LIST\n",
        "  sel_ARCH = ARCH_LIST[minInd_MSE]\n",
        "  model = model_arch(X_train, minInd_MSE, sel_ARCH)\n",
        "  return model\n",
        "\n",
        "def best_model_callback():\n",
        "  global dlMOD, TARGET\n",
        "  path = f\"/content/drive/MyDrive/Paper/02_Prediction - Model/{NAME_CASE}/Callback_{dlMOD} - {TARGET} - Best.keras\"\n",
        "  callback = [EarlyStopping(monitor=\"val_loss\", patience=PATIENT),\n",
        "              ModelCheckpoint(path, monitor=\"val_loss\", save_best_only=True, mode=\"min\")]\n",
        "  return callback\n",
        "\n",
        "def best_model_load():\n",
        "  global dlMOD, TARGET, NAME_CASE\n",
        "  model = load_model(f\"/content/drive/MyDrive/Paper/02_Prediction - Model/{NAME_CASE}/Callback_{dlMOD} - {TARGET} - Best.keras\")\n",
        "  return model\n",
        "\n",
        "def best_model_evaluation(model, X_train, y_train, X_val, y_val, ARCH_NO, fold):\n",
        "  global dlMOD, TARGET, NAME_CASE\n",
        "  list_df_X = [X_train, X_val]\n",
        "  list_df_y = [y_train, y_val]\n",
        "  df_eval = pd.DataFrame()\n",
        "  # >> Use MSE and MAPE for evaluation in this case\n",
        "  for i in range(2):\n",
        "    MSE_loss, MSE_metric, MAPE_metric = model.evaluate(list_df_X[i],list_df_y[i])\n",
        "    df = pd.DataFrame({\"MSE_loss\": [MSE_loss], \"MSE_metric\": [MSE_metric], \"MAPE_metric\": [MAPE_metric]})\n",
        "    df_eval = pd.concat([df_eval, df], axis=0)\n",
        "    df_eval = df_eval.rename(index={\"row1\": \"trainDataset\", \"row2\": \"valDataset\"})\n",
        "\n",
        "  df_eval.to_excel(f\"/content/drive/MyDrive/Paper/03_Prediction - Result/{NAME_CASE}/Loss Evaluation - {dlMOD} - {TARGET} - Best.xlsx\", index=False)"
      ],
      "metadata": {
        "id": "WQ3AeSY5Ravi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Run"
      ],
      "metadata": {
        "id": "6BnHxGNPnawl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =====[Import and pre-process dataset]=====\n",
        "X_t, y_t, num_SEQ = imp_trainData()\n",
        "\n",
        "randInd = random.sample(range(X_t.shape[0]), RATIO_num_val)\n",
        "randInd = sorted(randInd)\n",
        "print(randInd)\n",
        "\n",
        "X_val = X_t[randInd]\n",
        "y_val = y_t[randInd]\n",
        "\n",
        "X_train = np.delete(X_t, randInd, axis=0)\n",
        "y_train = np.delete(y_t, randInd, axis=0)\n",
        "\n",
        "df_valInd = pd.DataFrame(randInd)\n",
        "df_valInd.to_excel(f\"/content/drive/MyDrive/Paper/03_Prediction - Result/{NAME_CASE}/Index_validation - {dlMOD} - {TARGET} - Best.xlsx\", index=False)\n",
        "\n",
        "# =====[Find the best model]=====\n",
        "minInd_MSE, minInd_MAPE = best_eval()\n",
        "\n",
        "# =====[Training]=====\n",
        "model = best_model_arch(minInd_MSE)\n",
        "callback = best_model_callback()\n",
        "history = model_fitting(model, callback, X_train, y_train, X_val, y_val)\n",
        "\n",
        "# =====[Loss record]=====\n",
        "df_train, df_val = pd.DataFrame(), pd.DataFrame()\n",
        "df_train_loss, df_train_metric, df_val_loss, df_val_metric = pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n",
        "\n",
        "df_train_loss_new = pd.DataFrame(history.history[\"loss\"])\n",
        "df_train_loss = pd.concat([df_train_loss, df_train_loss_new], axis=1)\n",
        "df_val_loss_new = pd.DataFrame(history.history[\"val_loss\"])\n",
        "df_val_loss = pd.concat([df_val_loss, df_val_loss_new], axis=1)\n",
        "df_train_metric_new = pd.DataFrame(history.history[\"mape\"])\n",
        "df_train_metric = pd.concat([df_train_metric, df_train_metric_new], axis=1)\n",
        "df_val_metric_new = pd.DataFrame(history.history[\"val_mape\"])\n",
        "df_val_metric = pd.concat([df_val_metric, df_val_metric_new], axis=1)\n",
        "\n",
        "df_train_loss.to_excel(f\"/content/drive/MyDrive/Paper/03_Prediction - Result/{NAME_CASE}/Loss Record - {dlMOD} - {TARGET} - Best - train.xlsx\")\n",
        "df_val_loss.to_excel(f\"/content/drive/MyDrive/Paper/03_Prediction - Result/{NAME_CASE}/Loss Record - {dlMOD} - {TARGET} - Best - val.xlsx\")\n",
        "df_train_metric.to_excel(f\"/content/drive/MyDrive/Paper/03_Prediction - Result/{NAME_CASE}/Metric Record - {dlMOD} - {TARGET} - Best - train.xlsx\")\n",
        "df_val_metric.to_excel(f\"/content/drive/MyDrive/Paper/03_Prediction - Result/{NAME_CASE}/Metric Record - {dlMOD} - {TARGET} - Best - val.xlsx\")"
      ],
      "metadata": {
        "id": "41rRj2QJnaZD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}